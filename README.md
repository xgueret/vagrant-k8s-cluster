# ğŸš€ Cluster Kubernetes Local avec Vagrant et Ansible

![Stars](https://img.shields.io/github/stars/xgueret/vagrant-k8s-cluster?style=social) ![Last Commit](https://img.shields.io/github/last-commit/xgueret/vagrant-k8s-cluster) ![Status](https://img.shields.io/badge/Status-Active-brightgreen) ![License](https://img.shields.io/badge/License-MIT-blue)
![Terraform](https://img.shields.io/badge/Terraform-â‰¥1.11.0-623CE4) ![Ansible](https://img.shields.io/badge/Ansible-2.14+-EE0000)

DÃ©ployez un cluster Kubernetes complet en quelques minutes avec une automatisation complÃ¨te basÃ©e sur **Vagrant**, **Ansible**, et **kubeadm**.

## ğŸ“‹ Vue d'ensemble

Ce projet vous permet de crÃ©er un cluster Kubernetes local multi-nÅ“uds avec :
- **1 nÅ“ud de contrÃ´le** (k8s-controlplan)
- **2 nÅ“uds workers** (k8s-node1, k8s-node2)
- Runtime **containerd**
- RÃ©seau **Calico** (CNI)
- **Dashboard Kubernetes** et **Metrics Server** prÃ©installÃ©s

## âœ¨ FonctionnalitÃ©s

- ğŸ”§ **Automatisation complÃ¨te** avec Ansible (rÃ´les modulaires)
- ğŸŒ **RÃ©seau bridgÃ©** pour un accÃ¨s direct aux VMs
- ğŸ“Š **Monitoring** avec Dashboard et Metrics Server
- ğŸ›¡ï¸ **SÃ©curitÃ©** avec configuration des groupes systemd
- ğŸ¯ **PrÃªt pour la production** avec bonnes pratiques intÃ©grÃ©es
- ğŸ”„ **CI/CD ready** avec hooks pre-commit et linting

## ğŸ› ï¸ PrÃ©requis

### Logiciels requis
- [Vagrant](https://www.vagrantup.com/) â‰¥ 2.3
- [VirtualBox](https://www.virtualbox.org/) â‰¥ 7.0
- [Ansible](https://docs.ansible.com/) â‰¥ 2.9
- Python 3.8+

### Ressources systÃ¨me
- **RAM** : 8 Go minimum (16 Go recommandÃ©s)
- **CPU** : 4 cÅ“urs minimum
- **Stockage** : 20 Go d'espace libre

## ğŸš€ Installation et dÃ©marrage

### 1. Cloner le projet

```bash
git clone <votre-repo>/vagrant-k8s-cluster.git
cd vagrant-k8s-cluster
```

### 2. Installation des dÃ©pendances

```bash
# Installer les dÃ©pendances Python
pip install -r requirements.txt

# Configuration pre-commit (optionnel mais recommandÃ©)
pre-commit install
```

### 3. Configuration rÃ©seau

**Important** : Adaptez l'interface rÃ©seau dans le `Vagrantfile` :

```ruby
# Ligne 21 du Vagrantfile - remplacez "wlo1" par votre interface
node_config.vm.network "public_network", ip: node[:ip], bridge: "wlo1"
```

Pour identifier votre interface :
```bash
ip route | grep default
# ou
nmcli device status
```

### 4. DÃ©marrage du cluster

```bash
vagrant up
```

:hourglass: Le processus prend environ 10-15 minutes...

## ğŸ”§ Configuration

### Variables principales (`group_vars/all/main.yml`)

```yaml
k8s_release: "1.33"          # Version majeure de Kubernetes
k8s_version: "1.33.0"        # Version complÃ¨te
home_dir: "/home/vagrant"    # RÃ©pertoire utilisateur
```

### Adresses IP par dÃ©faut

| NÅ“ud | IP | RÃ´le |
|------|-----|------|
| k8s-controlplan | 192.168.1.70 | Control Plane |
| k8s-node1 | 192.168.1.71 | Worker |
| k8s-node2 | 192.168.1.72 | Worker |

## ğŸ“ Structure du projet

```
.
â”œâ”€â”€ Vagrantfile                    # Configuration des VMs
â”œâ”€â”€ playbook.yml                   # Playbook principal Ansible
â”œâ”€â”€ requirements.txt               # DÃ©pendances Python
â”œâ”€â”€ group_vars/all/main.yml       # Variables globales
â”œâ”€â”€ roles/                         # RÃ´les Ansible modulaires
â”‚   â”œâ”€â”€ cfg_nodes/                # Configuration de base des nÅ“uds
â”‚   â”œâ”€â”€ cfg_containerd/           # Installation containerd
â”‚   â”œâ”€â”€ cfg_kubeadm_kubelet_kubectl/ # Outils Kubernetes
â”‚   â”œâ”€â”€ inst_runc/                # Runtime runc
â”‚   â”œâ”€â”€ inst_cni/                 # Plugins CNI
â”‚   â”œâ”€â”€ inst_cri_tools/           # Outils CRI (crictl)
â”‚   â”œâ”€â”€ init_kubeadm/             # Initialisation du cluster
â”‚   â”œâ”€â”€ join_workers/             # Jointure des workers
â”‚   â””â”€â”€ kubectl_cheat_sheet/      # Configuration kubectl
â”œâ”€â”€ github/                       # Module Terraform (optionnel)
â””â”€â”€ .pre-commit-config.yaml      # Configuration qualitÃ© code
```

## ğŸ¯ Utilisation

### AccÃ¨s au cluster

```bash
# Se connecter au nÅ“ud maÃ®tre
vagrant ssh k8s-controlplan

# VÃ©rifier l'Ã©tat du cluster
kubectl get nodes
kubectl get pods -A
```

### Commandes utiles

```bash
# Gestion des VMs
vagrant up                    # DÃ©marrer toutes les VMs
vagrant up k8s-controlplan   # DÃ©marrer une VM spÃ©cifique
vagrant halt                 # ArrÃªter toutes les VMs
vagrant destroy -f           # Supprimer toutes les VMs
vagrant provision           # Reprovisioner sans recrÃ©er

# Debugging
vagrant status              # Ã‰tat des VMs
vagrant ssh k8s-node1      # Se connecter Ã  un worker
```

### AccÃ¨s au Dashboard Kubernetes

1. Se connecter au nÅ“ud de contrÃ´le :
```bash
vagrant ssh k8s-controlplan
```

2. CrÃ©er un tunnel pour accÃ©der au dashboard :
```bash
kubectl proxy --address='0.0.0.0' --accept-hosts='^.*$'
```

3. AccÃ©der via : `http://192.168.1.70:8001/api/v1/namespaces/kubernetes-dashboard/services/https:kubernetes-dashboard:/proxy/`

## ğŸ” Monitoring et debugging

### VÃ©rification de l'Ã©tat du cluster

```bash
# Ã‰tat des nÅ“uds
kubectl get nodes -o wide

# Ã‰tat des pods systÃ¨me
kubectl get pods -n kube-system

# MÃ©triques des nÅ“uds (nÃ©cessite metrics-server)
kubectl top nodes
kubectl top pods -A
```

### Logs et debugging

```bash
# Logs kubelet
sudo journalctl -u kubelet -f

# Logs containerd
sudo journalctl -u containerd -f

# Ã‰tat des services
sudo systemctl status kubelet
sudo systemctl status containerd
```

## ğŸ›¡ï¸ SÃ©curitÃ© et bonnes pratiques

### FonctionnalitÃ©s de sÃ©curitÃ© intÃ©grÃ©es

- Configuration systemd pour containerd et kubelet
- DÃ©sactivation du swap
- Configuration rÃ©seau sÃ©curisÃ©e
- Isolation des pods avec Calico

### Hooks de qualitÃ© de code

Le projet inclut des hooks pre-commit pour :
- Validation YAML/Ansible
- Linting du code shell
- VÃ©rification des clÃ©s privÃ©es
- Formatage automatique



## ğŸš¨ DÃ©pannage

### ProblÃ¨mes courants

#### 1. Ã‰chec de jointure des workers

```bash
# RÃ©gÃ©nÃ©rer le token de jointure
vagrant ssh k8s-controlplan
sudo kubeadm token create --print-join-command

# Reprovisioner un worker
vagrant provision k8s-node1
```

#### 2. ProblÃ¨mes rÃ©seau

```bash
# VÃ©rifier la connectivitÃ©
ping 192.168.1.70

# RedÃ©marrer les services rÃ©seau
sudo systemctl restart containerd kubelet
```

#### 3. Pods en erreur

```bash
# Diagnostic complet
kubectl describe node k8s-controlplan
kubectl get events --sort-by='.lastTimestamp'
```

### Logs dÃ©taillÃ©s

```bash
# Logs d'installation Ansible
vagrant up --debug

# Provisioning avec verbositÃ©
vagrant provision --debug
```



## ğŸ”„ DÃ©veloppement et contribution

### Tests locaux

```bash
# Validation des playbooks
ansible-lint playbook.yml

# Tests des hooks
pre-commit run --all-files
```

### Personnalisation

Pour modifier la configuration :

1. **Ressources VM** : Ã‰ditez le `Vagrantfile`
2. **Versions Kubernetes** : Modifiez `group_vars/all/main.yml`
3. **Composants supplÃ©mentaires** : Ajoutez des rÃ´les dans `roles/`

## ğŸ“š Documentation complÃ©mentaire

- [Documentation officielle Kubernetes](https://kubernetes.io/docs/)
- [Guide kubeadm](https://kubernetes.io/docs/setup/production-environment/tools/kubeadm/)
- [Documentation Calico](https://docs.projectcalico.org/)
- [Ansible best practices](https://docs.ansible.com/ansible/latest/user_guide/playbooks_best_practices.html)

## ğŸ¯ Roadmap

- [ ] IntÃ©gration Helm
- [ ] Monitoring avec Prometheus/Grafana
- [ ] Support LoadBalancer (MetalLB)
- [ ] Automatisation GitOps (ArgoCD)



## ğŸ‘¥ Contributors

- **Author**: Xavier GUERET
  [![GitHub followers](https://img.shields.io/github/followers/xgueret?style=social)](https://github.com/xgueret) [![Twitter Follow](https://img.shields.io/twitter/follow/xgueret?style=social)](https://x.com/hixmaster) [![LinkedIn](https://img.shields.io/badge/LinkedIn-Connect-blue?style=flat&logo=linkedin)](https://www.linkedin.com/in/xavier-gueret-47bb3019b/)

## âœ¨ Contributing

Contributions are welcome! Please feel free to submit a [Pull Request](https://github.com/xgueret/vagrant-k8s-cluster/pulls).
